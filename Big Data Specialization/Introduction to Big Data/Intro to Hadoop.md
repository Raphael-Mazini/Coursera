## Intro to Hadoop
<br>

_Correct answers are in **bold**._
<br>

**Question 1**. What does IaaS provide?

* **Hardware Only**

* Computing Environment

* Software On-Demand


**Question 2**. What does PaaS provide?

* Hardware Only

* **Computing Environment**

* Software On-Demand


**Question 3**. What does SaaS provide?

* Hardware Only

* Computing Environment

* **Software On-Demand**


**Question 4**. What are the two key components of HDFS and what are they used for?

* NameNode for block storage and Data Node for metadata.

* FASTA for genome sequence and Rasters for geospatial data.

* **NameNode for metadata and DataNode for block storage.**


**Question 5**. What is the job of the NameNode?

* **Coordinate operations and assigns tasks to Data Nodes**

* Listens from DataNode for block creation, deletion, and replication.

* For gene sequencing calculations.


**Question 6**. What is the order of the three steps to Map Reduce?

* Shuffle and Sort -> Map -> Reduce

* Shuffle and Sort -> Reduce -> Map

* **Map -> Shuffle and Sort -> Reduce**

* Map -> Reduce -> Shuffle and Sort


**Question 7**. What is a benefit of using pre-built Hadoop images?

* Quick prototyping, deploying, and guaranteed bug free.

* Less software choices to choose from.

* **Quick prototyping, deploying, and validating of projects.**

* Guaranteed hardware support.


**Question 8**. What are some examples of open-source tools built for Hadoop and what does it do?

* Giraph, for SQL-like queries.

* Pig, for real-time and in-memory processing of big data.

* **Zookeeper, management system for animal named related components.**

* Zookeeper, analyze social graphs.


**Question 9**. What is the difference between low level interfaces and high level interfaces?

* Low level deals with interactivity while high level deals with storage and scheduling.

* **Low level deals with storage and scheduling while high level deals with interactivity.**


**Question 10**. Which of the following are problems to look out for when integrating your project with Hadoop?

* Data Level Parallelism

* **Random Data Access**

* **Infrastructure Replacement**

* **Task Level Parallelism**

* **Advanced Alogrithms**


**Question 11**. As covered in the slides, which of the following are the major goals of Hadoop?

* Latency Sensitive Tasks

* **Enable Scalability**

* **Facilitate a Shared Environment**

* **Handle Fault Tolerance**

* **Optimized for a Variety of Data Types**

* **Provide Value for Data**


**Question 12**. What is the purpose of YARN?

* **Allows various applications to run on the same Hadoop cluster.**

* Enables large scale data across clusters.

* Implementation of Map Reduce.


**Question 13**. What are the two main components for a data computation framework that were described in the slides?

* **Resource Manager and Node Manager**

* Applications Master and Container

* Node Manager and Applications Master

* Node Manager and Container

* Resource Manager and Container

